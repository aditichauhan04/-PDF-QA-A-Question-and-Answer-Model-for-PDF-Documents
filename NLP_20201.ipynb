{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXmYMD8kdcbk",
        "outputId": "a5e0edbe-5808-405d-b75b-1bc238a02788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.33)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.43)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: hnswlib in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hnswlib) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.27.8\n",
        "!pip install tiktoken\n",
        "!pip install langchain\n",
        "!pip install hnswlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mlS7KLmfSOi",
        "outputId": "ff6b38ab-99d4-4377-b0b3-0fabbaef2e72"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import openai\n",
        "import hnswlib\n",
        "import langchain\n",
        "from langchain.text_splitter import TextSplitter, CharacterTextSplitter\n",
        "import PyPDF2\n",
        "import requests"
      ],
      "metadata": {
        "id": "pRzHXSMCdjcz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"\"\n",
        "openai_params = {\"model\":\"gpt-4-1106-preview\",\n",
        "                 \"temperature\":0.5,\n",
        "                 \"frequency_penalty\":0.0,\n",
        "                 \"presence_penalty\":0.0,\n",
        "                 \"max_tokens\":1500,\n",
        "                 \"top_p\":1}\n"
      ],
      "metadata": {
        "id": "lp2K0cSFgqWQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(prompt,openai_params):\n",
        "  message = [{\"role\":\"user\",\"content\":prompt}]\n",
        "  response = openai.ChatCompletion.create(messages=message,\n",
        "                                        **openai_params)\n",
        "\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "h3B55W2FduAa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text_gpt(content,chunk_size=120,splitter_pattern=\"\"):\n",
        "    \"\"\"\n",
        "    Tokenize the text according to openai tokenizer using Langchain\n",
        "    :param content:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if not splitter_pattern:\n",
        "\n",
        "        if \"\\n\\n\" in content:\n",
        "\n",
        "            text_splitter_ = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=0,encoding_name=\"cl100k_base\")\n",
        "        elif \"\\n\" in content:\n",
        "            text_splitter_ = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=0,\n",
        "                                                                         separator=\"\\n\",encoding_name=\"cl100k_base\")\n",
        "        else:\n",
        "            text_splitter_ = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=0,\n",
        "                                                                         separator=\" \",encoding_name=\"cl100k_base\")\n",
        "    else:\n",
        "        text_splitter_ = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size,chunk_overlap=0,\n",
        "                                                                    separator=splitter_pattern,encoding_name=\"cl100k_base\")\n",
        "    passages = text_splitter_.split_text(content)\n",
        "\n",
        "    return passages\n",
        "\n",
        "\n",
        "# tokenized_text = tokenize_text_by_page(text)\n",
        "# for page, tokens in tokenized_text.items():\n",
        "#     print(f\"Page {page}: {tokens}\\n\")"
      ],
      "metadata": {
        "id": "xbKiim4mduDA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_file_path):\n",
        "    # Open the PDF file\n",
        "    with open(pdf_file_path, 'rb') as file:\n",
        "        # Create PDF reader object\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "        extracted_text = \"\"\n",
        "\n",
        "        for page in pdf_reader.pages:\n",
        "\n",
        "            extracted_text += page.extract_text()\n",
        "\n",
        "        return extracted_text"
      ],
      "metadata": {
        "id": "g-iQkdqjd309"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index2(text_chunks):\n",
        "\n",
        "    embeddings = get_embedding_list(text_chunks)\n",
        "    if len(embeddings) == 0:\n",
        "        print(\"No embeddings generated.\")\n",
        "        return None, {}\n",
        "\n",
        "    dimension = len(embeddings[0])  # Dynamically get the dimension of embeddings\n",
        "\n",
        "    index1 = hnswlib.Index(space='l2', dim=dimension)\n",
        "    index1.init_index(max_elements=len(text_chunks), ef_construction=200, M=16)\n",
        "\n",
        "    # Bulk adding to the index\n",
        "    index1.add_items(embeddings)\n",
        "\n",
        "    index1.set_ef(50)\n",
        "    return index1"
      ],
      "metadata": {
        "id": "yhO7VBmPelgK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_list(texts, model=\"text-embedding-ada-002\"):\n",
        "  texts = [re.sub(\"\\n+\", \" \", text) for text in texts]\n",
        "  embedding_data = openai.Embedding.create(input = texts, model=model)['data']\n",
        "  print(\"embeddings returned from openai\")\n",
        "  return [embedding_data[i][\"embedding\"] for i in range(len(embedding_data))]\n",
        "\n",
        "\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "  text = re.sub(\"\\n+\", \" \", text)\n",
        "  return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
      ],
      "metadata": {
        "id": "CSzr3jfFev0f"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_similar_text2(query, index, top_k):\n",
        "    query_vector = get_embedding(query)\n",
        "    try:\n",
        "        labels, distances = index.knn_query(query_vector, k=top_k)\n",
        "\n",
        "        # Flatten the labels and distances since we have a single query\n",
        "        labels = labels.flatten()\n",
        "        distances = distances.flatten()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        results = []\n",
        "    return labels"
      ],
      "metadata": {
        "id": "OcnJWj_jeljA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_dict = extract_text_from_pdf(\"/content/Askmate IIIT Una .pdf\")\n",
        "chunks = tokenize_text_gpt(text_dict)"
      ],
      "metadata": {
        "id": "VQjUVeadfMxR"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfOaBLLWfuOR",
        "outputId": "aeb15d73-62bb-481d-c992-213c7b73b1a7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "index = create_index2(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o97icW6Peq6g",
        "outputId": "0903aab5-eec2-4a2b-e1b6-54395e4bcf1b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings returned from openai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Which is the literary club of IIIT Una?\""
      ],
      "metadata": {
        "id": "Bo5n0xDqeq9Y"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searched_index = search_similar_text2(query,index,10)"
      ],
      "metadata": {
        "id": "k6G40p8Meq_k"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\n",
        "for i in searched_index:\n",
        "  context = context + \" \" +chunks[i] + \"\\n\\n\""
      ],
      "metadata": {
        "id": "rYcqJDUlerB1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def qa_prompt(instruction, context):\n",
        "    _prompt = f\"\"\"When responding to instructions, always ensure your answers:\n",
        "1.Summarize key information from the provided documents to address the task directly.\n",
        "2.Identify and resolve any inconsistencies or inaccuracies between the instruction and the document content.\n",
        "3.Emphasize important details, removing unnecessary information for clarity.\n",
        "4.Note any missing content, suggesting alternatives or additional sources as necessary.\n",
        "5.Maintain accuracy in accordance with the document(s) content and ethical standards.\n",
        "6.Provide a concise summary of relevant insights from the document(s) related to the instruction.\n",
        "7.Include references with PDF names and page numbers for relevant excerpts that support your response.\n",
        "8.Tailor your response to the nature of the instruction, focusing on accuracy and relevance.\n",
        "\n",
        "Context:{context}\n",
        "Instruction:{instruction}\n",
        "\"\"\"\n",
        "    return _prompt\n"
      ],
      "metadata": {
        "id": "Ci0hUaAchXMH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fin_prompt = qa_prompt(query, context)\n",
        "generate_answer(fin_prompt,openai_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E5Ij31Fvhj-2",
        "outputId": "5cc70b44-9539-46e8-aec7-ac74b9a18797"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The literary club of IIIT Una is EUNOIA.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oFJ3xEaIhttM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}